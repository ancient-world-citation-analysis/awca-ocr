{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MakeGroundTruth\n",
    "\n",
    "In this notebook, a PDF and a corresponding CSV file are created. The CSV is guaranteed to contain the text that was used to generate the PDF.\n",
    "\n",
    "Due to space considerations, the output of this notebook will not be tracked in Git or GitHub. It will, however, be available via Google Drive.\n",
    "\n",
    "## Selection of Languages\n",
    "\n",
    "The languages used here are the top eleven languages when ordered by estimated literate population. Languages were chosen based on an estimate of those who could write them instead of those who could speak them for obvious reasons: We are interested in analyzing _writing_, not speech. These languages are\n",
    "1. Chinese (Mandarin)\n",
    "2. English\n",
    "3. Spanish\n",
    "4. Hindi\n",
    "5. Arabic\n",
    "6. French\n",
    "7. Russian\n",
    "8. Portuguese\n",
    "9. Japanese\n",
    "10. Bengali\n",
    "11. German\n",
    "\n",
    "This covers a variety of scripts: Chinese, Latin, Devanagari, Arabic, Cyrillic, Hiragana/Katakana, and Bengali. Furthermore, multiple variations of Latin, one of the most important scripts, will appear, including varied diacritics.\n",
    "\n",
    "Hebrew is not among these commonly written scripts; however, given the methods that we are using, we can infer that they will be likely to generalize well to correct handling of Hebrew if they can correctly handle the aforementioned scripts.\n",
    "\n",
    "Although Urdu appears in the source of this list, Urdu will be excluded because it is not written in Devanagari and so is a different language; furthermore, Urdu is less widely used than Hindi.\n",
    "\n",
    "Data is sourced from [this PDF](https://journal.lib.uoguelph.ca/index.php/perj/article/view/826/1358). This might not be a reliable source, and it is known to be only approximate. However, this source is perfectly transparent about its sources (primarily the CIA), as well as the assumptions/approximations used in synthesizing its estimates. I propose that we regard the data as both trustworthy and sufficiently accurate for the purpose of deciding which languages to include in our benchmark."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collection of Text\n",
    "\n",
    "I endeavor to collect about 1000 pages of text from Wikipedia in each of these 11 languages. This will give on the order of 10<sup>5</sup> pages of text in total. This is about 3 million characters of each language.\n",
    "\n",
    "The ISO 639-1 language codes associated with each of these languages are:\n",
    "1. Chinese: zh\n",
    "2. English: en\n",
    "3. Spanish: es\n",
    "4. Hindi: hi\n",
    "5. Arabic: ar\n",
    "6. French: fr\n",
    "7. Russian: ru\n",
    "8. Portuguese: pt\n",
    "9. Japanese: ja\n",
    "10. Bengali: bn\n",
    "11. German: de"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}